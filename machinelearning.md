Aquí tienes una tabla comparativa de los principales modelos de aprendizaje supervisado:  

| **Modelo**               | **Métricas Importantes**                              | **Explicación y Fórmula**                                             | **Hiperparámetros**                               | **Usos**                                        | **Pasos Previos (EDA y Preprocesamiento)**     |
|--------------------------|------------------------------------------------------|------------------------------------------------------------------------|-------------------------------------------------|------------------------------------------------|------------------------------------------------|
| **Regresión Lineal**     | MSE, RMSE, R²                                       | Modela la relación entre variables dependientes e independientes mediante una ecuación lineal. **Fórmula:**  \( y = \beta_0 + \beta_1x + \epsilon \) | Alpha (regularización)                          | Predicción de valores continuos (precio de casas, ventas) | - Manejo de valores nulos  - Eliminación de outliers  - Normalización/Estandarización  - Análisis de correlación |
| **Regresión Logística**  | Accuracy, Precision, Recall, F1-score, AUC-ROC      | Clasifica datos en dos categorías usando una función sigmoide. **Fórmula:**  \( P(y=1) = \frac{1}{1+e^{-(\beta_0 + \beta_1x)}} \) | C (inversa de la regularización), Solver       | Clasificación binaria (detección de fraudes, enfermedades) | - Balanceo de clases - Conversión de variables categóricas - Normalización de variables numéricas |
| **Árboles de Decisión**  | Accuracy, Gini, Entropía                            | Crea una estructura jerárquica dividiendo los datos en función de características relevantes. **Fórmula:** Gini \( = 1 - \sum p_i^2 \) | Profundidad, Número de nodos, Criterio (Gini/Entropía) | Clasificación y regresión (diagnóstico médico, crédito bancario) | - Manejo de valores nulos - Codificación de variables categóricas |
| **Random Forest**        | Accuracy, RMSE, R², OOB Score                       | Ensamble de múltiples árboles de decisión que mejora la precisión y evita sobreajuste. | Número de árboles, Profundidad máxima, Número de características seleccionadas | Predicción en datos complejos, clasificación y regresión (clima, precios de mercado) | - Conversión de variables categóricas - Manejo de datos faltantes - Normalización |
| **SVM (Máquinas de Soporte Vectorial)** | Accuracy, Precision, Recall, AUC-ROC | Encuentra el hiperplano óptimo para clasificar los datos. **Fórmula:** \( f(x) = w \cdot x + b \) | Kernel (lineal, RBF, polinomial), C, Gamma | Clasificación en datos con fronteras complejas (biometría, detección de spam) | - Estandarización de datos - Conversión de variables categóricas |
| **k-NN (k-Nearest Neighbors)** | Accuracy, Precision, Recall | Asigna una clase a una instancia según sus k vecinos más cercanos. **Distancia Euclidiana:** \( d(p,q) = \sqrt{\sum (q_i - p_i)^2} \) | Número de vecinos (k), Distancia (Euclídea, Manhattan) | Clasificación y regresión (recomendaciones, diagnóstico médico) | - Normalización/Estandarización - Conversión de variables categóricas |
| **Redes Neuronales**     | Accuracy, Loss Function, AUC-ROC                    | Modela relaciones complejas a través de capas de neuronas interconectadas. **Fórmula:** \( y = f(WX + B) \) donde \( f \) es una función de activación | Número de capas, Número de neuronas, Learning Rate, Función de activación | Reconocimiento de imágenes, procesamiento de lenguaje natural | - Normalización - Balanceo de clases - Conversión de variables categóricas - Creación de embeddings |







